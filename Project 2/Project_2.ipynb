{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMS-1yo4Tqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "2b67fedd-d7cf-42b1-c289-a98b9ffcff4e"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# normalize inputs\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# test to make sure it will fit in model\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Create the baseline model\n",
        "def model1():\n",
        "    model = Sequential()\n",
        "    #Convolutional input layer composed of 32 feature maps, rectifier activation function and a weight constraint of max set to 3.\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Another Convolutional input layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "    #Max pooling layer\n",
        "    model.add(MaxPooling2D())\n",
        "    #Flatten layer out before inputting\n",
        "    model.add(Flatten())\n",
        "    #Connected output layer with softmax activation function0\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    #Compile model\n",
        "    epochs = 25\n",
        "    l_rate = .01\n",
        "    decay = l_rate / epochs\n",
        "    sgd = SGD(lr=l_rate, momentum=0.9, decay=decay, nesterov=False)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    #Fit the model\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
        "\n",
        "    #Final evaluation of the model\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
        "\n",
        "\n",
        "   \n",
        "    # accuracy (3 epoch) = 58.46%\n",
        "    # accuracy (10 epoch) = 61.21%\n",
        "    # accuracy (25 epoch) = 67.19%\n",
        "\n",
        "\n",
        "\n",
        "# Fine-tuned model number one (More layers + binary crossentropy)\n",
        "def model2():\n",
        "    model = Sequential()\n",
        "    #Convolutional input layer composed of 32 feature maps, rectifier activation function and a weight constraint of max set to 3.\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Another convolutional layer with relu activation function, and constraint\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "    #Max pooling layer\n",
        "    model.add(MaxPooling2D())\n",
        "    #Another convolutional layer , but with 128 feature maps, and with relu activation function, no constraints\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    #Another convolutional layer , with 32 feature maps, and with relu activation function, no constraints\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    #Max pooling layer\n",
        "    model.add(MaxPooling2D())\n",
        "    #Fully connected layer, 512 nodes and relu activation function\n",
        "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    #ANother dropout layer, this time set to 50%\n",
        "    model.add(Dropout(0.5))\n",
        "    #Flatten out before inputting\n",
        "    model.add(Flatten())\n",
        "    #Connected output layer with softmax activation function\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    #Compile model\n",
        "    epochs = 25\n",
        "    l_rate = .01\n",
        "    decay = l_rate / epochs\n",
        "    sgd = SGD(lr=l_rate, momentum=0.9, decay=decay, nesterov=False)\n",
        "    #Compiled with binary crossentropy\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    #Fit the model\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
        "\n",
        "    #Final evaluation of the model\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
        "\n",
        "    # accuracy (3 epoch) = 91.24%\n",
        "    # accuracy (10 epoch) = 92.14%\n",
        "    # accuracy (25 epoch) = 93.08%\n",
        "\n",
        "\n",
        "\n",
        "# Fine-tuned model number two (Full of layers)\n",
        "def model3():\n",
        "    model = Sequential()\n",
        "    #Convolutional input layer composed of 32 feature maps (3x3), rectifier activation function and a weight constraint of max set to 3.\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Another convolutional layer , with 32 feature maps (3x3), and with relu activation function, no constraints\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    #Max pooling layer\n",
        "    model.add(MaxPooling2D())\n",
        "    #Another convolutional layer , with 64 feature maps (3x3), and with relu activation function, no constraints\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Another convolutional layer , with 64 feature maps (3x3), and with relu activation function, no constraints\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    #Max pooling layer\n",
        "    model.add(MaxPooling2D())\n",
        "    #Another convolutional layer , with 128 feature maps (3x3), and with relu activation function, no constraints\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Another convolutional layer , with 128 feature maps (3x3), and with relu activation function, no constraints\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    #Max pooling layer\n",
        "    model.add(MaxPooling2D())\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Fully connected layer, 1024 nodes and relu activation function\n",
        "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Fully connected layer, 512 nodes and relu activation function\n",
        "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    #Dropout - 20%\n",
        "    model.add(Dropout(0.2))\n",
        "    #Flatten out before inputting\n",
        "    model.add(Flatten())\n",
        "    #Connected output layer with softmax activation function\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    #Compile model\n",
        "    epochs = 25\n",
        "    lrate = 0.01\n",
        "    decay = lrate / epochs\n",
        "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    #Fit the model\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n",
        "    #Final evaluation of the model\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
        "\n",
        "    # accuracy (3 epoch) = 47.90%\n",
        "    # accuracy (10 epoch) = 66.62%\n",
        "    # accuracy (25 epoch) = 78.82%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Prints base model\n",
        "print(model1())\n",
        "#Uncomment to print model 2 (base model + binary crossentropy + some layers)\n",
        "#print(model2())\n",
        "#Uncomment to print model 3 (base model + a ton more layers)\n",
        "#print(model3())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "(50000, 10)\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_73 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 10)                81930     \n",
            "=================================================================\n",
            "Total params: 92,074\n",
            "Trainable params: 92,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "41472/50000 [=======================>......] - ETA: 1s - loss: 1.7296 - acc: 0.3852"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-3c15d3b854d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m#print(model3())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-3c15d3b854d9>\u001b[0m in \u001b[0;36mmodel1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eORz-Q_W4WgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXCNFCnaT2MH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}
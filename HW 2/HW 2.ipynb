{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[[ 0.02185476]\n",
      " [ 0.10580907]\n",
      " [-0.14051814]]\n",
      "Final outputs are:\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iteration:  1\n",
      "[[ 0.02185476]\n",
      " [ 0.10580907]\n",
      " [-0.04051814]]\n",
      "Final outputs are:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iteration:  2\n",
      "[[ 0.02185476]\n",
      " [ 0.10580907]\n",
      " [-0.04051814]]\n",
      "Final outputs are:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iteration:  3\n",
      "[[ 0.02185476]\n",
      " [ 0.10580907]\n",
      " [-0.04051814]]\n",
      "Final outputs are:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iteration:  4\n",
      "[[ 0.02185476]\n",
      " [ 0.10580907]\n",
      " [-0.04051814]]\n",
      "Final outputs are:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iteration:  5\n",
      "[[ 0.02185476]\n",
      " [ 0.10580907]\n",
      " [-0.04051814]]\n",
      "Final outputs are:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "class pcn:\n",
    "    #\"\"\" A basic Perceptron (the same pcn.py except with the weights printed\n",
    "    #and it does not reorder the inputs)\"\"\"\n",
    "\n",
    "    def __init__(self,inputs,targets):\n",
    "       # \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        if ndim(inputs)>1:\n",
    "            self.nIn = shape(inputs)[1]\n",
    "        else: \n",
    "            self.nIn = 1\n",
    "\n",
    "        if ndim(targets)>1:\n",
    "            self.nOut = shape(targets)[1]\n",
    "        else:\n",
    "            self.nOut = 1\n",
    "\n",
    "        self.nData = shape(inputs)[0]\n",
    "\n",
    "        # Initialise network\n",
    "        self.weights = random.rand(self.nIn+1,self.nOut)*0.1-0.05\n",
    "\n",
    "    def pcntrain(self,inputs,targets,eta,nIterations):\n",
    "       # \"\"\" Train the thing \"\"\"\t\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = concatenate((inputs,-ones((self.nData,1))),axis=1)\n",
    "\n",
    "        # Training\n",
    "        change = range(self.nData)\n",
    "\n",
    "        for n in range(nIterations):\n",
    "\n",
    "            self.outputs = self.pcnfwd(inputs);\n",
    "            self.weights += eta*dot(transpose(inputs),targets-self.outputs)\n",
    "            print (\"Iteration: \", n)\n",
    "            print (self.weights)\n",
    "\n",
    "            activations = self.pcnfwd(inputs)\n",
    "            print (\"Final outputs are:\")\n",
    "            print (activations)\n",
    "        #return self.weights\n",
    "\n",
    "    def pcnfwd(self,inputs):\n",
    "        #\"\"\" Run the network forward \"\"\"\n",
    "\n",
    "        outputs =  dot(inputs,self.weights)\n",
    "        outputs *= 6\n",
    "\n",
    "        #Changed the 3rd element\n",
    "        return where(outputs>.333,1,0)\n",
    "\n",
    "\n",
    "    def confmat(self,inputs,targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = concatenate((inputs,-ones((self.nData,1))),axis=1)\n",
    "        outputs = dot(inputs,self.weights)\n",
    "\n",
    "        nClasses = shape(targets)[1]\n",
    "\n",
    "        if nClasses==1:\n",
    "            nClasses = 2\n",
    "            outputs = where(outputs>0,1,0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = argmax(outputs,1)\n",
    "            targets = argmax(targets,1)\n",
    "\n",
    "        cm = zeros((nClasses,nClasses))\n",
    "        for i in range(nClasses):\n",
    "            for j in range(nClasses):\n",
    "                cm[i,j] = sum(where(outputs==i,1,0)*where(targets==j,1,0))\n",
    "\n",
    "        print (cm)\n",
    "        print (trace(cm)/sum(cm))\n",
    "        \n",
    "        \n",
    "import numpy as np\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "targets = np.array([[0],[1],[1],[1]])\n",
    "\n",
    "p = pcn(inputs, targets)\n",
    "p.pcntrain(inputs, targets, 0.1, 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including the two schools that are free:\n",
      "Predicted Outputs:  [122.77047616 122.03979849 122.05448389 124.56928069 124.56928069\n",
      " 121.91897479 121.84523263 122.0755981  122.02297015 121.13390439]\n",
      "Beta:  [-6.30274887e-05 -1.24569281e+02]\n",
      "[-6.30274887e-05 -1.24569281e+02]\n",
      "---------------------------------\n",
      "Without the two schools that are free:\n",
      "Predicted Outputs:  [134.18328839 123.6949001  123.90569925 121.96055693 120.90203763\n",
      " 124.20877956 123.45334057 110.69139757]\n",
      "Beta:  [-9.04717354e-04 -1.60003922e+02]\n",
      "[-9.04717354e-04 -1.60003922e+02]\n"
     ]
    }
   ],
   "source": [
    "#Tuition is independent var\n",
    "#Salary is dependent var\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#didn't use sklearn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "x = np.array([28540, 40133, 39900, 0, 0, 42050, 43220, 39565, 40400, 54506]).reshape((-1, 1))\n",
    "y = np.array([137, 135, 127, 122, 120, 118, 118, 117, 117, 114])\n",
    "\n",
    "x_new = np.array([28540, 40133, 39900, 42050, 43220, 39565, 40400, 54506]).reshape((-1, 1))\n",
    "y_new = np.array([137, 135, 127, 118, 118, 117, 117, 114])\n",
    "\n",
    "#print(x)\n",
    "#print(y)\n",
    "\n",
    "def linreg(inputs, targets):\n",
    "    inputs = np.concatenate((inputs, -np.ones((np.shape(inputs)[0],1))),axis = 1)\n",
    "    beta = np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(inputs),inputs)), np.transpose(inputs)),targets)\n",
    "    outputs = np.dot(inputs,beta)\n",
    "    #print(shape(beta))\n",
    "    print('Predicted Outputs: ', outputs)\n",
    "    print('Beta: ', beta)\n",
    "    return beta\n",
    "\n",
    "\n",
    "#model = LinearRegression()\n",
    "#model.fit(x, y)\n",
    "#model = LinearRegression().fit(x, y)\n",
    "#r_sq = model.score(x, y)\n",
    "\n",
    "print('Including the two schools that are free:')\n",
    "print(linreg(x,y))\n",
    "#print('coefficient of determination (with two free schools):', r_sq)\n",
    "#print('intercept (with two free schools):', model.intercept_)\n",
    "#print('slope (with two free schools):', model.coef_)\n",
    "#y_pred = y_pred = model.intercept_ + model.coef_ * x\n",
    "#print('predicted response (with two free schools):', y_pred, sep='\\n')\n",
    "\n",
    "print('---------------------------------')\n",
    "print('Without the two schools that are free:')\n",
    "\n",
    "print(linreg(x_new,y_new))\n",
    "\n",
    "#model.fit(x_new, y_new)\n",
    "#model = LinearRegression().fit(x_new, y_new)\n",
    "#r_sq = model.score(x_new, y_new)\n",
    "#print('coefficient of determination:', r_sq)\n",
    "#print('intercept:', model.intercept_)\n",
    "#print('slope:', model.coef_)\n",
    "#y_pred = y_pred = model.intercept_ + model.coef_ * x_new\n",
    "#print('predicted response:', y_pred, sep='\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results (problem 2):\n",
    "If we remove both schools with a free tuition, we get a new slope of y=-0.000904x (calulcated), correlation coefficient of .71 (calculated), and coefficient of determinism of .50976 (calculated). Because of this, we can say that there is a fairly strong linear association between tuition costs and salaries. It predicted much better without the two schools, meaning they are outliers. \n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check attached image\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) \n",
    "Yes I'd use supervised learning. I can use the existing data as training data \n",
    "for my new model, which will use regression. Split the dates up (of power consumption) into month and day for the input. I'll use my old data to find a slope, and \n",
    "have it predict new values based on the model that fits the slope. I could also use the demand of the next 5 days as the target outputs and make a linear actuvation function for the output. Another parameter could be consumption based on location.\n",
    "\n",
    "\n",
    "## b) \n",
    "You would be able to integrate it into your data and have it further improve the \n",
    "accuracy of calculations and predictions. It could be predicted that when weather is \n",
    "good, there is less consumption of power, and when it is bad there is more. It could be\n",
    "another input node included in the initial prediction.\n",
    "\n",
    "\n",
    "## c) \n",
    "It would work well in 'normal' areas, and most likely predict correctly for most places. \n",
    "But there are areas where this MLP would fail; such as a newly built power plant, newly built\n",
    "office buildings, farmlands, and changes in the geographical features of the land.  \n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This MLP will have 5 inputs and 1 bias (arbitrary number), so 5 total inputs. Inputs would consist of number of people in the ward per week, the average temp at night, the average temp during the day, the season, whether or not there is an epidemic, and the bias. The number of hidden neurons in the hidden layer will amount to 1/10 multiplied by the number of epochs. This (the number of hidden nodes) was caluclated based off of the formula (posted below) learned in class. The number of epochs would be equal to 5 years, so either 260 weeks, 60 months, or 1820 days (5 wouldn't be large enough.) We chose 5 years because of the data collection time frame. We will need to preprocess any numeric data to standardize it (hrough normalization) and make sure it is numerically consistent. I would expect this MLP to work because of the structure of the network and the data given.\n",
    "\n",
    "\n",
    "Formula for calculation of number of hidden nodes: (x+b) * k + 1 * k = 1/10(N)\n",
    "   \n",
    "    x = # of inputs\n",
    "    b = bias\n",
    "    k = # of neurons\n",
    "    N = epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)\n",
    "   1. Orange\n",
    "   2. Red\n",
    "   3. Red\n",
    "   \n",
    "If all of the neighbors in the plot have the same weight, the point 'U' would be classified as Red. This is because the three closest points to 'U' include one orange point, and two red points.\n",
    "    \n",
    "\n",
    "## 2)\n",
    "\n",
    "## formula = sqrrt((y2-y1)^2 + (x2-x1))\n",
    "## Applied Euclidean:\n",
    "- red1 = sqrrt((2-4)^2 + (1-1)^2) = sqrrt(4)\n",
    "- red2 = sqrrt((6-4)^2 + (2-1)^2) = sqrrt(5)\n",
    "- orange1 = sqrrt((5-4)^2 + (2-1)^2) = sqrrt(2)\n",
    "\n",
    "## Then take inverse square:\n",
    "- 1/(red1+red2)^2 = 1/9\n",
    "- 1/(orange1)^2 = 1/2\n",
    "\n",
    "1/2 > 1/9\n",
    "\n",
    "\n",
    "If the vote is made according to the inverse square of distantce, the prediction will be orange. This is because when you run the distances through the euclidean algorithm, then take the inverse square of them, you get 1/2 for orange and 1/9 for red. Because the orange value is bigger than red, it is classified as orange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
